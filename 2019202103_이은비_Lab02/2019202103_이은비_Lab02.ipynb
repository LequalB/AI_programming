{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FJtFvXZqYCDz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "# digits.data from sklearn contains 1797 images of 8x8 pixels\n",
        "# Each image has a hand-written digit\n",
        "digits_df = digits.images.reshape((len(digits.target), -1))\n",
        "digits_tf = digits.target\n",
        "\n",
        "# Splitting dataframe into train & test\n",
        "X_train_org, X_test_org, y_train_num, y_test = train_test_split(digits_df, digits_tf, test_size= 0.20, random_state= 101)\n",
        "\n",
        "# Digits data has range of [0,16], which often lead too big exponential values\n",
        "# so make them normal distribution of [0,1] with the sklearn package, or you can just divide them by 16\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train_org)\n",
        "X_test = sc.transform(X_test_org)\n",
        "\n",
        "n_classes = 10\n",
        "\n",
        "# Transform Nx1 Y vector into Nx10 answer vector, so that we can perform one-to-all classification\n",
        "y_train = np.zeros((y_train_num.shape[0],10))\n",
        "for i in range(n_classes):\n",
        "    y_train[:,i] = (y_train_num == i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions for the forwardpath\n",
        "def sigmoid(x): # sigmoid function\n",
        "    # Numerically stable with large exponentials\n",
        "    x = np.where(x < 0, np.exp(x)/(1 + np.exp(x)), 1/(1 + np.exp(-x)))\n",
        "    return x\n",
        "\n",
        "def softmax(x): #softmax function\n",
        "    # Numerically stable with large exponentials\n",
        "    x = x - np.max(x, axis=-1, keepdims=True)\n",
        "    x = np.exp(x)\n",
        "    xs = np.sum(x, axis=-1, keepdims=True)\n",
        "    return x / xs"
      ],
      "metadata": {
        "id": "YUMIeboXYNvG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits_df.shape)  # 2D ndarray size of digits_df's shape\n",
        "print(X_train.shape)    # 2D ndarray size of X_train's shape\n",
        "print(y_train.shape)    # 2D ndarray size of y_train's shape\n",
        "print(X_train_org[0])   # print array\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])   # print the arbitrary number\n",
        "dimage = X_train_org[idx].reshape((8,8))\n",
        "plt.matshow(dimage)\n",
        "plt.gray()\n",
        "plt.show()\n",
        "print('The number is', y_train_num[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "-UrgsyqTYQz1",
        "outputId": "6e30473c-7929-4ba1-d535-116a81bc7f73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n",
            "(1437, 64)\n",
            "(1437, 10)\n",
            "[ 0.  0.  0.  9. 16.  6.  0.  0.  0.  0.  4. 15.  6. 15.  0.  0.  0.  0.\n",
            "  8. 11.  9. 11.  0.  0.  0.  0.  8. 16. 14.  2.  0.  0.  0.  0. 11. 16.\n",
            " 13.  0.  0.  0.  0.  6. 14.  2. 12.  9.  0.  0.  0.  5. 16. 11.  5. 13.\n",
            "  4.  0.  0.  0.  3.  8. 13. 16.  9.  0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number is 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myDenseLayer:\n",
        "    def __init__(self, n_out, n_in):\n",
        "        self.wegt = np.zeros((n_out, n_in))\n",
        "        self.bias = np.zeros((n_out))\n",
        "\n",
        "    def forward(self, x):                      # (b, i)\n",
        "        ### START CODE HERE ###\n",
        "        x_lin = (self.wegt @x.T).T + self.bias  # Linear Prediction\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "        return x_lin\n",
        "\n",
        "    def backward(self, x, x_in):  # x = dJ/dz (b, c)\n",
        "        ### START CODE HERE ###\n",
        "\n",
        "        dw = x.T @ x_in   # Gradients for weights\n",
        "        db = np.sum(x, axis=0)  # Gradients for biases\n",
        "        wdJdz =  x @ self.wegt # Propagation for lower layer\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "        return dw, db, wdJdz"
      ],
      "metadata": {
        "id": "_6ExAq_WYuK1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)   # set the random seed\n",
        "\n",
        "tmp = myDenseLayer(3,5)\n",
        "tmp.wegt = np.random.randn(3,5)\n",
        "tmp.bias = np.random.randn(3)\n",
        "\n",
        "print(tmp.forward(np.random.randn(2,5,3))) # print out the result through the forward function."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbS7alhmYyWJ",
        "outputId": "4b490a85-99cf-472f-a4de-783a2d1ec068"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 3.23890168  3.05091188 -3.32627831]\n",
            "  [ 0.388114    3.36724875  1.06158492]\n",
            "  [ 3.10267869  1.87570497 -1.8326582 ]]\n",
            "\n",
            " [[-7.60581826  2.36703751 -1.16423539]\n",
            "  [ 3.48035012  2.41940644 -0.13917734]\n",
            "  [ 1.20541315  2.07585619 -1.5435161 ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# activation functions for the backpropagation.\n",
        "def dJdz_sigmoid(wdJdz_upper, az):\n",
        "    dJdz = wdJdz_upper * az * (1 - az)    # backpropagation through activation function\n",
        "    return dJdz\n",
        "\n",
        "def dJdz_softmax(y_hat, y):\n",
        "    dJdz = y_hat - y   # backpropagation through activation function\n",
        "    return dJdz"
      ],
      "metadata": {
        "id": "64QH6dz2o2XB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)   # set the random seed\n",
        "\n",
        "print(dJdz_sigmoid(np.random.randn(3),np.random.randn(3)))  # print out the value through dJdz_sigmoid function.\n",
        "print(dJdz_softmax(np.random.randn(3),np.random.randn(3)))  # print out the value through dJdz_softmax function."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gcnUFQho3ON",
        "outputId": "c837c58f-b164-4adf-dab0-64fef22a246b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-4.90531647 -0.64834065 -1.89126428]\n",
            "[ 0.53948992 -0.29540078 -1.55749236]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_forward(l1, l2, l3, X_in):\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    a_1 = sigmoid(l1.forward(X_in))         # first stage forward\n",
        "    a_2 = sigmoid(l2.forward(a_1))          # second stage forward\n",
        "    a_3 = softmax(l3.forward(a_2))          # third stage forward\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return a_1, a_2, a_3\n",
        "\n",
        "def my_backward(l1, l2, l3, a_1, a_2, a_3, X_in, y_true):\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Calculate gradients in reverse order (backpropagation)\n",
        "    dJdz_3 = dJdz_softmax(a_3, y_true) # define the dJdz_3 value through the dJdz_softmax function.\n",
        "    dw_3, db_3, wdJdz_3 = l3.backward(dJdz_3, a_2)  # go through 3rd stage backward\n",
        "\n",
        "    dJdz_2 = dJdz_sigmoid(wdJdz_3, a_2) # define the dJdz_2 value through the dJdz_sigmoid function.\n",
        "    dw_2, db_2, wdJdz_2 = l2.backward(dJdz_2, a_1)   # go through 2nd stage backward\n",
        "\n",
        "    dJdz_1 = dJdz_sigmoid(wdJdz_2, a_1) # define the dJdz_1 value through the dJdz_sigmoid function.\n",
        "    dw_1, db_1, _ = l1.backward(dJdz_1, X_in)    # go through 1st stage backward\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    d_1 = [dw_1, db_1]  # assigning values set the data type.\n",
        "    d_2 = [dw_2, db_2]\n",
        "    d_3 = [dw_3, db_3]\n",
        "\n",
        "    return d_1, d_2, d_3\n",
        "\n",
        "def my_loss(l1, l2, l3, X_in, y_true):\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    a_1, a_2, a_3 = my_forward(l1, l2, l3, X_in)    # Assign each returned value to each variable\n",
        "    loss = -np.mean(np.sum(y_true * np.log(a_3), axis=1))                  # calculate loss\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return loss\n",
        "\n",
        "def my_predict(l1, l2, l3, X_in):\n",
        "    ### START CODE HERE ###\n",
        "    a_1, a_2, a_3 = my_forward(l1, l2, l3, X_in)    # Assign each returned value to each variable\n",
        "    pred = np.argmax(a_3, axis=1)                   # make prediction\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return pred"
      ],
      "metadata": {
        "id": "AqqTLAbTJ8LR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_inputs  = 64  # set the parameters\n",
        "n_hidden1 = 80\n",
        "n_hidden2 = 70\n",
        "n_classes = 10\n",
        "\n",
        "l1 = myDenseLayer(n_hidden1, n_inputs)  # set the layer1 through myDenseLayer function\n",
        "l2 = myDenseLayer(n_hidden2, n_hidden1) # set the layer2 through myDenseLayer function\n",
        "l3 = myDenseLayer(n_classes, n_hidden2) # set the layer3 through myDenseLayer function.\n",
        "\n",
        "print(X_train.shape, y_train.shape) # print out the shape of X_train, y_train\n",
        "print(l1.wegt.shape, l1.bias.shape) # print out the shape of l1's weight and l1's bias\n",
        "print(l2.wegt.shape, l2.bias.shape) # print out the shape of l2's weight and l1's bias\n",
        "print(l3.wegt.shape, l3.bias.shape) # print out the shape of l3's weight and l1's bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAVLEx96o9ia",
        "outputId": "403ca736-9145-45bb-91d9-5fd9790b7377"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1437, 64) (1437, 10)\n",
            "(80, 64) (80,)\n",
            "(70, 80) (70,)\n",
            "(10, 70) (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights are initialized to...\n",
        "l1.wegt = np.random.randn(n_hidden1, n_inputs)\n",
        "l2.wegt = np.random.randn(n_hidden2, n_hidden1)\n",
        "l3.wegt = np.random.randn(n_classes, n_hidden2)"
      ],
      "metadata": {
        "id": "rUubPNy8o_IG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the parameters\n",
        "alpha = 0.01 # alpha: learning rate\n",
        "n_epochs = 5000\n",
        "n_train = X_train.shape[0]\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Forward Path\n",
        "    a_1, a_2, a_3 = my_forward(l1, l2, l3, X_train)  # forward path, assuming you have defined my_forward function\n",
        "\n",
        "    # Backward Path\n",
        "    d_1, d_2, d_3 = my_backward(l1, l2, l3, a_1, a_2, a_3, X_train, y_train)  # backward path, assuming you have defined my_backward function\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    dw_1, db_1 = d_1\n",
        "    dw_2, db_2 = d_2\n",
        "    dw_3, db_3 = d_3\n",
        "\n",
        "    # Update weights and biases\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    l3.wegt = l3.wegt - alpha * dw_3  # Update weights of layer 3\n",
        "    l3.bias = l3.bias - alpha * db_3  # Update biases of layer 3\n",
        "    l2.wegt = l2.wegt - alpha * dw_2  # Update weights of layer 2\n",
        "    l2.bias = l2.bias - alpha * db_2  # Update biases of layer 2\n",
        "    l1.wegt = l1.wegt - alpha * dw_1  # Update weights of layer 1\n",
        "    l1.bias = l1.bias - alpha * db_1  # Update biases of layer 1\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Print loss\n",
        "    if ((epoch+1) % 500 == 0):\n",
        "        loss_J = my_loss(l1, l2, l3, X_train, y_train)\n",
        "        print('Epoch: %4d,  loss: %10.8f' % (epoch+1, loss_J))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuHufeOFFog0",
        "outputId": "0f8caa4f-9590-44dd-fa45-d460a780aee9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  500,  loss: 0.03927880\n",
            "Epoch: 1000,  loss: 0.01282518\n",
            "Epoch: 1500,  loss: 0.00482432\n",
            "Epoch: 2000,  loss: 0.00283907\n",
            "Epoch: 2500,  loss: 0.00198707\n",
            "Epoch: 3000,  loss: 0.00148731\n",
            "Epoch: 3500,  loss: 0.00113596\n",
            "Epoch: 4000,  loss: 0.00089513\n",
            "Epoch: 4500,  loss: 0.00072707\n",
            "Epoch: 5000,  loss: 0.00060800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = my_predict(l1, l2, l3, X_test)\n",
        "\n",
        "accuracy_score(y_pred, y_test)  # calculate accuracy with two values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rI7rAN7pDnZ",
        "outputId": "98e10359-500b-4aa6-bc12-403f3036e200"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9638888888888889"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(80, 70, ), activation='logistic', solver='sgd', \\\n",
        "                    alpha=0.01, learning_rate_init=0.01, max_iter=1000)\n",
        "\n",
        "# Training/Fitting the Model\n",
        "mlp.fit(X_train, y_train_num)\n",
        "\n",
        "# Making Predictions\n",
        "s_pred = mlp.predict(X_test)\n",
        "accuracy_score(s_pred, y_test)  # calculate accuracy with two values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCyApKt_pFCB",
        "outputId": "af66cd73-a5e1-42ae-f21f-f416f521fd23"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.randint(X_test.shape[0])\n",
        "dimage = X_test_org[idx].reshape((8,8))\n",
        "plt.gray()\n",
        "plt.matshow(dimage)\n",
        "plt.show()\n",
        "\n",
        "X_input = np.expand_dims(X_test[idx], 0)    # expand the dimension to make the input data.\n",
        "\n",
        "y_pred = my_predict(l1, l2, l3, X_input)    # calculate the prediction value.\n",
        "\n",
        "s_pred = mlp.predict(X_input)\n",
        "# print out all the values.\n",
        "print('My prediction is ' + str(y_pred[0]))\n",
        "print('sk prediction is ' + str(s_pred[0]))\n",
        "print('Actual number is ' + str(y_test[idx]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "_yImXJ_0pFsd",
        "outputId": "ab982125-0853-48e1-a332-a92cc3b1ef2f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My prediction is 3\n",
            "sk prediction is 3\n",
            "Actual number is 3\n"
          ]
        }
      ]
    }
  ]
}